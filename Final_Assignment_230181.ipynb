{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data for class 0. Press 'm' to start capturing.\n",
      "Collecting data for class 1. Press 'm' to start capturing.\n",
      "Collecting data for class 2. Press 'm' to start capturing.\n",
      "Collecting data for class 3. Press 'm' to start capturing.\n",
      "Collecting data for class 4. Press 'm' to start capturing.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Define parameters\n",
    "number_of_classes = 5  # Adjust based on your dataset\n",
    "class_images = 1000  # Number of images per class\n",
    "data_dir = \"data\"  # Directory to store the captured images\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "for j in range(number_of_classes):\n",
    "    # Create directory for each class\n",
    "    class_dir = os.path.join(data_dir, str(j))\n",
    "    if not os.path.exists(class_dir):\n",
    "        os.makedirs(class_dir)\n",
    "\n",
    "    print(f\"Collecting data for class {j}. Press 'm' to start capturing.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.putText(frame, \"Press 'm' to capture\", (100, 50), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    1.3, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        if cv2.waitKey(25) == ord('m'):\n",
    "            break\n",
    "\n",
    "    counter = 0\n",
    "    while counter < class_images:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        cv2.waitKey(25)\n",
    "        cv2.imwrite(os.path.join(class_dir, f'{counter}.jpg'), frame)\n",
    "        counter += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.5)\n",
    "\n",
    "data_dir = './data'\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for dir in os.listdir(data_dir):\n",
    "    for img_path in os.listdir(os.path.join(data_dir, dir)):\n",
    "        auxdata = []\n",
    "\n",
    "        img = cv2.imread(os.path.join(data_dir, dir, img_path))\n",
    "        imgrgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = hands.process(imgrgb)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                for lm in hand_landmarks.landmark:\n",
    "                    auxdata.extend([lm.x, lm.y, lm.z])\n",
    "            data.append(auxdata)\n",
    "            labels.append(int(dir))\n",
    "\n",
    "# Save processed data\n",
    "with open('landmarks.pkl', 'wb') as f:\n",
    "    pickle.dump({'data': data, 'labels': labels}, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest model saved as RandomForest_model.pkl\n",
      "KNeighbors model saved as KNeighbors_model.pkl\n",
      "LogisticRegression model saved as LogisticRegression_model.pkl\n",
      "The best model is RandomForest with an accuracy score of 1.0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the data that was previously processed\n",
    "with open('landmarks.pkl', 'rb') as f:\n",
    "    data_dict = pickle.load(f)\n",
    "\n",
    "data = np.asarray(data_dict['data'])\n",
    "labels = np.asarray(data_dict['labels'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, shuffle=True, stratify=labels)\n",
    "\n",
    "# Initialize the classifiers\n",
    "RF_model = RandomForestClassifier()\n",
    "KNN_model = KNeighborsClassifier()\n",
    "LR_model = LogisticRegression(max_iter=1000)  # Increased max_iter for convergence if needed\n",
    "\n",
    "# Fit models on the training data and evaluate their accuracy\n",
    "models = [RF_model, KNN_model, LR_model]\n",
    "model_names = ['RandomForest', 'KNeighbors', 'LogisticRegression']\n",
    "scores = []\n",
    "\n",
    "for model in models:\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "# Identify the best model based on accuracy\n",
    "best_model_index = np.argmax(scores)\n",
    "best_model_name = model_names[best_model_index]\n",
    "best_model_score = scores[best_model_index]\n",
    "\n",
    "# Train all models on the full dataset and save them\n",
    "for model, name in zip(models, model_names):\n",
    "    model.fit(data, labels)\n",
    "    filename = f'{name}_model.pkl'\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f'{name} model saved as {filename}')\n",
    "\n",
    "# Print the best model and its accuracy\n",
    "print(f'The best model is {best_model_name} with an accuracy score of {best_model_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained best model\n",
    "model = pickle.load(open('LogisticRegression_model.pkl', 'rb'))\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize Mediapipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(static_image_mode=False, min_detection_confidence=0.2)\n",
    "\n",
    "# Label dictionary for A-Z\n",
    "labels_dict = {i: chr(i + 65) for i in range(26)}\n",
    "\n",
    "while True:\n",
    "    data_aux = []\n",
    "    x_ = []\n",
    "    y_ = []\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    H, W, _ = frame.shape\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = hands.process(frame_rgb)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                x = lm.x\n",
    "                y = lm.y\n",
    "                z = lm.z  # Include the z-coordinate\n",
    "                x_.append(x)\n",
    "                y_.append(y)\n",
    "\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                data_aux.append(lm.x - min(x_))  # Normalize x-coordinate\n",
    "                data_aux.append(lm.y - min(y_))  # Normalize y-coordinate\n",
    "                data_aux.append(lm.z)  # Include the z-coordinate without normalization\n",
    "\n",
    "            # Draw the hand landmarks on the frame\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(0, 0, 255), circle_radius=2)\n",
    "            )\n",
    "\n",
    "        # Get the bounding box for the hand\n",
    "        x1 = int(min(x_) * W) - 10\n",
    "        x2 = int(max(x_) * W) + 10\n",
    "        y1 = int(min(y_) * H) - 10\n",
    "        y2 = int(max(y_) * H) + 10\n",
    "\n",
    "        if len(data_aux) == 63:  # Ensure there are 63 features for prediction\n",
    "            # Predict the class of the hand sign using the best model\n",
    "            pred = model.predict([np.asarray(data_aux)])\n",
    "            pred_char = labels_dict[int(pred[0])]  # Get the predicted character\n",
    "\n",
    "            # Draw a rectangle and display the predicted character\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "            cv2.putText(frame, pred_char, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    # Show the frame with the predicted character\n",
    "    cv2.imshow('Sign Detected', frame)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('e'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained best model\n",
    "model = pickle.load(open('KNeighbors_model.pkl', 'rb'))\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize Mediapipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(static_image_mode=False, min_detection_confidence=0.3)\n",
    "\n",
    "# Label dictionary for A-Z\n",
    "labels_dict = {i: chr(i + 65) for i in range(26)}\n",
    "\n",
    "while True:\n",
    "    data_aux = []\n",
    "    x_ = []\n",
    "    y_ = []\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    H, W, _ = frame.shape\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = hands.process(frame_rgb)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                x = lm.x\n",
    "                y = lm.y\n",
    "                z = lm.z  # Include the z-coordinate\n",
    "                x_.append(x)\n",
    "                y_.append(y)\n",
    "\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                data_aux.append(lm.x - min(x_))  # Normalize x-coordinate\n",
    "                data_aux.append(lm.y - min(y_))  # Normalize y-coordinate\n",
    "                data_aux.append(lm.z)  # Include the z-coordinate without normalization\n",
    "\n",
    "            # Draw the hand landmarks on the frame\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(0, 0, 255), circle_radius=2)\n",
    "            )\n",
    "\n",
    "        # Get the bounding box for the hand\n",
    "        x1 = int(min(x_) * W) - 10\n",
    "        x2 = int(max(x_) * W) + 10\n",
    "        y1 = int(min(y_) * H) - 10\n",
    "        y2 = int(max(y_) * H) + 10\n",
    "\n",
    "        if len(data_aux) == 63:  # Ensure there are 63 features for prediction\n",
    "            # Predict the class of the hand sign using the best model\n",
    "            pred = model.predict([np.asarray(data_aux)])\n",
    "            pred_char = labels_dict[int(pred[0])]  # Get the predicted character\n",
    "\n",
    "            # Draw a rectangle and display the predicted character\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "            cv2.putText(frame, pred_char, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    # Show the frame with the predicted character\n",
    "    cv2.imshow('Sign Detected', frame)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('e'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained best model\n",
    "model = pickle.load(open('RandomForest_model.pkl', 'rb'))\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize Mediapipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(static_image_mode=False, min_detection_confidence=0.3)\n",
    "\n",
    "# Label dictionary for A-Z\n",
    "labels_dict = {i: chr(i + 65) for i in range(26)}\n",
    "\n",
    "while True:\n",
    "    data_aux = []\n",
    "    x_ = []\n",
    "    y_ = []\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    H, W, _ = frame.shape\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = hands.process(frame_rgb)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                x = lm.x\n",
    "                y = lm.y\n",
    "                z = lm.z  # Include the z-coordinate\n",
    "                x_.append(x)\n",
    "                y_.append(y)\n",
    "\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                data_aux.append(lm.x - min(x_))  # Normalize x-coordinate\n",
    "                data_aux.append(lm.y - min(y_))  # Normalize y-coordinate\n",
    "                data_aux.append(lm.z)  # Include the z-coordinate without normalization\n",
    "\n",
    "            # Draw the hand landmarks on the frame\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(0, 255, 0), circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(0, 0, 255), circle_radius=2)\n",
    "            )\n",
    "\n",
    "        # Get the bounding box for the hand\n",
    "        x1 = int(min(x_) * W) - 10\n",
    "        x2 = int(max(x_) * W) + 10\n",
    "        y1 = int(min(y_) * H) - 10\n",
    "        y2 = int(max(y_) * H) + 10\n",
    "\n",
    "        if len(data_aux) == 63:  # Ensure there are 63 features for prediction\n",
    "            # Predict the class of the hand sign using the best model\n",
    "            pred = model.predict([np.asarray(data_aux)])\n",
    "            pred_char = labels_dict[int(pred[0])]  # Get the predicted character\n",
    "\n",
    "            # Draw a rectangle and display the predicted character\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "            cv2.putText(frame, pred_char, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    # Show the frame with the predicted character\n",
    "    cv2.imshow('Sign Detected', frame)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('e'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
